# ========================================
# CogniTwin LLM Council Configuration
# ========================================

# -----------------
# LLM Configuration
# -----------------

# Enable real LLM integration (set to 'true' to use OpenAI GPT-4)
# When false, uses rule-based deterministic agents (faster, free, predictable)
# When true, uses real LLM API calls (more creative, requires API key, costs money)
USE_REAL_LLM=false

# OpenAI API Key (required if USE_REAL_LLM=true)
# Get your key from: https://platform.openai.com/api-keys
OPENAI_API_KEY=your_openai_api_key_here

# LLM Model to use
# Options:
#   - gpt-4-turbo-preview (recommended - most capable, ~$0.01/1K tokens)
#   - gpt-4 (capable but slower)
#   - gpt-3.5-turbo (faster, cheaper ~$0.001/1K tokens, less capable)
LLM_MODEL=gpt-4-turbo-preview

# -----------------
# Service Configuration
# -----------------

# Port for LLM Council Orchestrator
PORT=4000

# Forecasting Service URL
FORECASTING_SERVICE_URL=http://localhost:8001

# -----------------
# Cost Estimation
# -----------------
# With GPT-4-turbo-preview:
# - Each agent call: ~500-1500 tokens = $0.005 - $0.015
# - Full 5-agent simulation: ~$0.025 - $0.075
# - Per day (100 simulations): ~$2.50 - $7.50
#
# With GPT-3.5-turbo:
# - Each agent call: ~$0.0005 - $0.0015
# - Full 5-agent simulation: ~$0.0025 - $0.0075
# - Per day (100 simulations): ~$0.25 - $0.75

# -----------------
# Advanced Options
# -----------------

# Logging level (debug, info, warn, error)
LOG_LEVEL=info

# Enable request logging
ENABLE_REQUEST_LOGGING=true
